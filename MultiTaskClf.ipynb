{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install proglearn\n",
        "!pip install git+https://github.com/neurodata/treeple.git"
      ],
      "metadata": {
        "id": "JxBYpMdVyY57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9aeb37bb-581e-4004-cdb2-5319dc898023"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: proglearn in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: tensorflow>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from proglearn) (2.18.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from proglearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from proglearn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from proglearn) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.11/dist-packages (from proglearn) (2.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->proglearn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.19.0->proglearn) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.19.0->proglearn) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.19.0->proglearn) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.19.0->proglearn) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.19.0->proglearn) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.19.0->proglearn) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.19.0->proglearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.19.0->proglearn) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.19.0->proglearn) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.19.0->proglearn) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.19.0->proglearn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.19.0->proglearn) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=1.19.0->proglearn) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.19.0->proglearn) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.19.0->proglearn) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.19.0->proglearn) (0.1.2)\n",
            "Collecting git+https://github.com/neurodata/treeple.git\n",
            "  Cloning https://github.com/neurodata/treeple.git to /tmp/pip-req-build-w7n461wi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neurodata/treeple.git /tmp/pip-req-build-w7n461wi\n",
            "  Resolved https://github.com/neurodata/treeple.git to commit 75c2cf919939574e4240fe261f053162039495cf\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from treeple==0.10.3) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from treeple==0.10.3) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from treeple==0.10.3) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->treeple==0.10.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->treeple==0.10.3) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from treeple import ObliqueRandomForestClassifier\n",
        "from proglearn.sims import generate_gaussian_parity\n",
        "from sklearn.metrics import accuracy_score\n",
        "from proglearn.sims import generate_spirals\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "R9G4oQOFqN-d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskForestClassifier:\n",
        "    def __init__(self, clf_type=\"SPORF\", **kwargs):\n",
        "        if clf_type == \"SPORF\":\n",
        "            self.model_cls = ObliqueRandomForestClassifier\n",
        "            self.default_params = {\n",
        "                \"n_estimators\": 200,\n",
        "                \"feature_combinations\": 2.0,\n",
        "                \"max_depth\": 20,\n",
        "                \"min_samples_split\": 5,\n",
        "                \"min_samples_leaf\": 1,\n",
        "                \"max_features\": 0.5,\n",
        "                \"bootstrap\": True\n",
        "            }\n",
        "        elif clf_type == \"MORF\":\n",
        "            self.model_cls = MORFClassifier  # Liora\n",
        "            self.default_params = { ... }\n",
        "        elif clf_type == \"HonestForest\":\n",
        "            self.model_cls = HonestForestClassifier  # Riya\n",
        "            self.default_params = { ... }\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported tree: {clf_type}\")\n",
        "\n",
        "        self.params = {**self.default_params, **kwargs}\n",
        "        self.model = None\n",
        "        self.task_data = {}\n",
        "\n",
        "    def add_task(self, task_id, X, y):\n",
        "        self.task_data[task_id] = (X, y)\n",
        "\n",
        "    def fit(self, task_ids):\n",
        "        X_all, y_all, task_labels = [], [], []\n",
        "        for task_id in task_ids:\n",
        "            X, y = self.task_data[task_id]\n",
        "            X_all.append(X)\n",
        "            y_all.append(y)\n",
        "            task_labels.append(np.full(len(y), task_id))\n",
        "\n",
        "        X_all = np.vstack(X_all)\n",
        "        y_all = np.concatenate(y_all)\n",
        "        task_labels = np.concatenate(task_labels)\n",
        "        X_all = np.column_stack((X_all, task_labels))\n",
        "\n",
        "        self.model = self.model_cls(**self.params, random_state=42)\n",
        "        self.model.fit(X_all, y_all)\n",
        "\n",
        "    def predict(self, X, task_id):\n",
        "        X_task = np.column_stack((X, np.full(len(X), task_id)))\n",
        "        return self.model.predict(X_task)\n",
        "\n",
        "    def score(self, X, y, task_id):\n",
        "        return accuracy_score(y, self.predict(X, task_id))\n",
        "\n",
        "    def evaluate_transfer_general(self, forward_train_ids, forward_test_id, backward_train_ids, backward_test_ids, do_reverse=False):\n",
        "        \"\"\"\n",
        "        - Forward: train on `forward_train_ids`, test on `forward_test_id`\n",
        "        - Backward: train on `backward_train_ids`, test individually on each in `backward_test_ids`\n",
        "        - Reverse (not mandatory. default as False but can change to true): train on `forward_test_id`, test on `forward_train_ids`\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Forward\n",
        "        self.fit(forward_train_ids)\n",
        "        X_test, y_test = self.task_data[forward_test_id]\n",
        "        forward_acc = self.score(X_test, y_test, task_id=forward_test_id)\n",
        "        results[\"forward_transfer\"] = {\n",
        "            \"train_on\": forward_train_ids,\n",
        "            \"test_on\": forward_test_id,\n",
        "            \"accuracy\": forward_acc\n",
        "        }\n",
        "\n",
        "        # Backward\n",
        "        self.fit(backward_train_ids)\n",
        "        backward_accuracies = {}\n",
        "        for tid in backward_test_ids:\n",
        "            X, y = self.task_data[tid]\n",
        "            backward_accuracies[f\"task{tid}\"] = {\n",
        "                \"train_on\": backward_train_ids,\n",
        "                \"test_on\": tid,\n",
        "                \"accuracy\": self.score(X, y, task_id=tid)\n",
        "            }\n",
        "        results[\"backward_transfer\"] = backward_accuracies\n",
        "\n",
        "        # Reverse\n",
        "        if do_reverse:\n",
        "            self.fit([forward_test_id])\n",
        "            reverse_accuracies = {}\n",
        "            for tid in forward_train_ids:\n",
        "                X, y = self.task_data[tid]\n",
        "                reverse_accuracies[f\"task{tid}\"] = {\n",
        "                    \"train_on\": [forward_test_id],\n",
        "                    \"test_on\": tid,\n",
        "                    \"accuracy\": self.score(X, y, task_id=tid)\n",
        "                }\n",
        "            results[\"reverse_transfer\"] = reverse_accuracies\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "EH1kTXubBcsK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTing"
      ],
      "metadata": {
        "id": "nZ2fDAqB5Tdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XOR/RXOR\n"
      ],
      "metadata": {
        "id": "lRjYmHNl7-U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_xor, y_xor = generate_gaussian_parity(1000)\n",
        "X_rxor, y_rxor = generate_gaussian_parity(1000, angle_params=np.pi / 4)\n",
        "X_train_xor, X_test_xor, y_train_xor, y_test_xor = train_test_split(X_xor, y_xor, test_size=0.2, random_state=42)\n",
        "X_train_rxor, X_test_rxor, y_train_rxor, y_test_rxor = train_test_split(X_rxor, y_rxor, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1ifFdkSq5TCK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train on same task and test on the same task (like a base line)"
      ],
      "metadata": {
        "id": "kn74DRo68aDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultiTaskForestClassifier(clf_type=\"SPORF\")\n",
        "clf.add_task(0, X_train_xor, y_train_xor)\n",
        "clf.add_task(1, X_train_rxor, y_train_rxor)\n",
        "clf.fit([0, 1])\n",
        "acc_xor = clf.score(X_test_xor, y_test_xor, task_id=0)\n",
        "acc_rxor = clf.score(X_test_rxor, y_test_rxor, task_id=1)\n",
        "\n",
        "print(f\"XOR Accuracy: {acc_xor:.3f}\")\n",
        "print(f\"RXOR Accuracy: {acc_rxor:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZsElMQ88HKO",
        "outputId": "0fbefa97-cae0-4058-cf3d-064ed5ca0581"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Accuracy: 0.935\n",
            "RXOR Accuracy: 0.970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(clf.evaluate_transfer_general)"
      ],
      "metadata": {
        "id": "LGGs-JR5AMex",
        "outputId": "bef8daa8-02e0-4eaa-f14e-41afc43d0361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method evaluate_transfer_general in module __main__:\n",
            "\n",
            "evaluate_transfer_general(forward_train_ids, forward_test_id, backward_train_ids, backward_test_ids, do_reverse=False) method of __main__.MultiTaskForestClassifier instance\n",
            "    - Forward: train on `forward_train_ids`, test on `forward_test_id`\n",
            "    - Backward: train on `backward_train_ids`, test individually on each in `backward_test_ids`\n",
            "    - Reverse (optional): train on `forward_test_id`, test on `forward_train_ids`\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward training, backward training, reverse training"
      ],
      "metadata": {
        "id": "UrnIBOB3FGR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = clf.evaluate_transfer_general(\n",
        "    forward_train_ids=[0],\n",
        "    forward_test_id=1,\n",
        "    backward_train_ids=[0, 1],\n",
        "    backward_test_ids=[0, 1],\n",
        "    do_reverse=True\n",
        ")\n",
        "\n",
        "print(\"Transfer Learning Results:\")\n",
        "fwd = results[\"forward_transfer\"]\n",
        "print(f\"\\n Forward Transfer:\\n  Train on: {fwd['train_on']}\\n  Test on: {fwd['test_on']}\\n  Accuracy: {fwd['accuracy']:.3f}\")\n",
        "\n",
        "print(\"\\n Backward Transfer:\")\n",
        "for task, stats in results[\"backward_transfer\"].items():\n",
        "    print(f\"  {task}:\")\n",
        "    print(f\"    Train on: {stats['train_on']}\")\n",
        "    print(f\"    Test on : {stats['test_on']}\")\n",
        "    print(f\"    Accuracy: {stats['accuracy']:.3f}\")\n",
        "\n",
        "if \"reverse_transfer\" in results:\n",
        "    print(\"\\n Reverse Transfer:\")\n",
        "    for task, stats in results[\"reverse_transfer\"].items():\n",
        "        print(f\"  {task}:\")\n",
        "        print(f\"    Train on: {stats['train_on']}\")\n",
        "        print(f\"    Test on : {stats['test_on']}\")\n",
        "        print(f\"    Accuracy: {stats['accuracy']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1FAFm5i79cj",
        "outputId": "3be43b22-a5e7-446d-fc7e-5bc35a6bf361"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer Learning Results:\n",
            "\n",
            " Forward Transfer:\n",
            "  Train on: [0]\n",
            "  Test on: 1\n",
            "  Accuracy: 0.546\n",
            "\n",
            " Backward Transfer:\n",
            "  task0:\n",
            "    Train on: [0, 1]\n",
            "    Test on : 0\n",
            "    Accuracy: 0.978\n",
            "  task1:\n",
            "    Train on: [0, 1]\n",
            "    Test on : 1\n",
            "    Accuracy: 0.991\n",
            "\n",
            " Reverse Transfer:\n",
            "  task0:\n",
            "    Train on: [1]\n",
            "    Test on : 0\n",
            "    Accuracy: 0.516\n"
          ]
        }
      ]
    }
  ]
}