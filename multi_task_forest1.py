# -*- coding: utf-8 -*-
"""MultiTaskClf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d7ipMRMx9b10KeaPRe-yLQq5tAo6Wnvd
"""

import numpy as np
from sklearn.metrics import accuracy_score
from treeple import ObliqueRandomForestClassifier

class MultiTaskForestClassifier:
    def __init__(self, clf_type="SPORF", **kwargs):
        if clf_type == "SPORF":
            self.model_cls = ObliqueRandomForestClassifier
            self.default_params = {
                "n_estimators": 200,
                "feature_combinations": 2.0,
                "max_depth": 20,
                "min_samples_split": 5,
                "min_samples_leaf": 1,
                "max_features": 0.5,
                "bootstrap": True
            }
        elif clf_type == "MORF":
            self.model_cls = MORFClassifier  # Liora
            self.default_params = { ... }
        elif clf_type == "HonestForest":
            self.model_cls = HonestForestClassifier  # Riya
            self.default_params = { ... }
        else:
            raise ValueError(f"Unsupported tree: {clf_type}")

        self.params = {**self.default_params, **kwargs}
        self.model = None
        self.task_data = {}

    def add_task(self, task_id, X, y):
        self.task_data[task_id] = (X, y)

    def fit(self, task_ids):
        X_all, y_all, task_labels = [], [], []
        for task_id in task_ids:
            X, y = self.task_data[task_id]
            X_all.append(X)
            y_all.append(y)
            task_labels.append(np.full(len(y), task_id))

        X_all = np.vstack(X_all)
        y_all = np.concatenate(y_all)
        task_labels = np.concatenate(task_labels)
        X_all = np.column_stack((X_all, task_labels))

        self.model = self.model_cls(**self.params, random_state=42)
        self.model.fit(X_all, y_all)

    def predict(self, X, task_id):
        X_task = np.column_stack((X, np.full(len(X), task_id)))
        return self.model.predict(X_task)

    def score(self, X, y, task_id):
        return accuracy_score(y, self.predict(X, task_id))

    def evaluate_transfer_general(self, forward_train_ids, forward_test_id, backward_train_ids, backward_test_ids, do_reverse=False):
        """
        - Forward: train on `forward_train_ids`, test on `forward_test_id`
        - Backward: train on `backward_train_ids`, test individually on each in `backward_test_ids`
        - Reverse (not mandatory. default as False but can change to true): train on `forward_test_id`, test on `forward_train_ids`
        """
        results = {}

        # Forward
        self.fit(forward_train_ids)
        X_test, y_test = self.task_data[forward_test_id]
        forward_acc = self.score(X_test, y_test, task_id=forward_test_id)
        results["forward_transfer"] = {
            "train_on": forward_train_ids,
            "test_on": forward_test_id,
            "accuracy": forward_acc
        }

        # Backward
        self.fit(backward_train_ids)
        backward_accuracies = {}
        for tid in backward_test_ids:
            X, y = self.task_data[tid]
            backward_accuracies[f"task{tid}"] = {
                "train_on": backward_train_ids,
                "test_on": tid,
                "accuracy": self.score(X, y, task_id=tid)
            }
        results["backward_transfer"] = backward_accuracies

        # Reverse
        if do_reverse:
            self.fit([forward_test_id])
            reverse_accuracies = {}
            for tid in forward_train_ids:
                X, y = self.task_data[tid]
                reverse_accuracies[f"task{tid}"] = {
                    "train_on": [forward_test_id],
                    "test_on": tid,
                    "accuracy": self.score(X, y, task_id=tid)
                }
            results["reverse_transfer"] = reverse_accuracies

        return results